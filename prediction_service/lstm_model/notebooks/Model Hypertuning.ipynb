{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def create_split(df, pct_train, pct_val, batch_size, window_size):\n",
    "    length = df.shape[0]\n",
    "    temp_train_size = find_batch_gcd(math.floor(pct_train * length), batch_size)\n",
    "    test_size = length - temp_train_size\n",
    "    train_size = find_batch_gcd(math.floor((1 - pct_val) * temp_train_size), batch_size)\n",
    "    val_size = temp_train_size - train_size\n",
    "    df_train = df[:- val_size - test_size]\n",
    "    df_val = df[- val_size - test_size - window_size:- test_size]\n",
    "    df_test = df[- test_size - window_size:]\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "def find_batch_gcd(length, batch_size):\n",
    "    while length % batch_size != 0:\n",
    "        length -= 1\n",
    "    return length\n",
    "\n",
    "def create_dataset(df, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(df) - window_size):\n",
    "        v = df.iloc[i:(i + window_size)].values\n",
    "        X.append(v)\n",
    "        y.append(df[\"Close\"].iloc[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def create_multi_pred_dataset(df, window_size, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(df) - window_size - time_steps - 1):\n",
    "        v = df.iloc[i:(i + window_size)].values\n",
    "        X.append(v)\n",
    "        y.append(df[\"Close\"].iloc[i + window_size:i + window_size + time_steps].values)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def create_model(nodes, optimizer, dropout, X_train):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(nodes[0], input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "    model.add(LSTM(nodes[1], return_sequences=True))\n",
    "    model.add(LSTM(nodes[2]))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(nodes[3]))\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def flatten_prediction(pred, pred_count, time_steps):\n",
    "    print(pred_count, pred.shape[0])\n",
    "    pred = pred[::time_steps]\n",
    "    pred = pred.flatten()\n",
    "    if pred_count < pred.shape[0]:\n",
    "        pred = pred[:pred_count - pred.shape[0]]\n",
    "    return pred\n",
    "\n",
    "def evaluate_forecast(pred, actual):\n",
    "    mse = mean_squared_error(pred, actual)\n",
    "    print(\"Test Mean Squared Error:\", mse)\n",
    "    mae = mean_absolute_error(pred, actual)\n",
    "    print(\"Test Mean Absolute Error:\", mae)\n",
    "    return\n",
    "\n",
    "def train_model(pair, batch_size, window_size, nodes_arr, optimizer, dropout, epochs):\n",
    "    series = pd.read_csv(\"../data/processed/{}_processed.csv\".format(pair))\n",
    "    \n",
    "    buy = pair[:3]\n",
    "    sell = pair[3:]\n",
    "    \n",
    "    series = series[series.shape[0] % batch_size:]\n",
    "    close = series[['Real Close']]\n",
    "\n",
    "    series = series.drop(['Time', 'Real Close'], axis=1)\n",
    "    series = series[['Close', 'EMA_10', 'EMA_50', 'RSI', 'A/D Index',\n",
    "                     '{} Interest Rate'.format(buy), '{} Interest Rate'.format(sell), '{}_CPI'.format(buy), '{}_CPI'.format(sell),\n",
    "                     '{} Twitter Sentiment'.format(buy), '{} Twitter Sentiment'.format(sell),\n",
    "                     '{} News Sentiment'.format(buy), '{} News Sentiment'.format(sell),\n",
    "                     #'EUR_GDP', 'USD_GDP', 'EUR_PPI', 'USD_PPI', 'USD Unemployment Rate', 'EUR Unemployment Rate'\n",
    "                    ]]\n",
    "\n",
    "    df_train, df_val, df_test = create_split(series, 0.75, 0.1, batch_size, window_size)\n",
    "    print(f'df_train.shape {df_train.shape}, df_validation.shape {df_val.shape}, df_test.shape {df_test.shape}')\n",
    "\n",
    "    closeScaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    featureScaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    df_train = df_train.copy()\n",
    "    df_val = df_val.copy()\n",
    "    df_test = df_test.copy()\n",
    "    df_train.loc[:, ['Close']] = closeScaler.fit_transform(df_train[['Close']])\n",
    "    df_train.loc[:, ~df_train.columns.isin(['Close'])] = featureScaler.fit_transform(df_train.loc[:, ~df_train.columns.isin(['Close'])])\n",
    "    df_val.loc[:, ['Close']] = closeScaler.transform(df_val[['Close']])\n",
    "    df_val.loc[:, ~df_val.columns.isin(['Close'])] = featureScaler.transform(df_val.loc[:, ~df_val.columns.isin(['Close'])])\n",
    "    df_test.loc[:, ['Close']] = closeScaler.transform(df_test[['Close']])\n",
    "    df_test.loc[:, ~df_test.columns.isin(['Close'])] = featureScaler.transform(df_test.loc[:, ~df_test.columns.isin(['Close'])])\n",
    "\n",
    "    #X_train, y_train = create_dataset(df_train, window_size)\n",
    "    #X_val, y_val = create_dataset(df_val, window_size)\n",
    "    #X_test, y_test = create_dataset(df_test, window_size)\n",
    "    \n",
    "    X_train, y_train = create_multi_pred_dataset(df_train, window_size, nodes_arr[3])\n",
    "    X_val, y_val = create_multi_pred_dataset(df_val, window_size, nodes_arr[3])\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_val.shape)\n",
    "    print(y_val.shape)\n",
    "    #X_test, y_test = create_multi_pred_dataset(df_test, window_size, nodes_arr[3])\n",
    "\n",
    "    model = create_model(nodes_arr, optimizer, dropout, X_train)\n",
    "    \n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    log_dir = \"logs/tuning/\" + current_time\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, update_freq='epoch', profile_batch=0, histogram_freq=1)\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=False,\n",
    "                    #callbacks=[tensorboard_callback]\n",
    "                   )\n",
    "    \n",
    "    return model, closeScaler, featureScaler\n",
    "\n",
    "def visualize_loss(history):\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    ax1 = fig.subplots(1)\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set(xlabel='Epoch', ylabel='Loss')\n",
    "    ax1.plot(history.history['loss'], label='Train Loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Val Loss')\n",
    "    ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(pair, window_size, batch_size, time_steps, model, scaler, fScaler):\n",
    "    buy = pair[:3]\n",
    "    sell = pair[3:]\n",
    "\n",
    "    series = pd.read_csv(\"../data/processed/{}_processed.csv\".format(pair))\n",
    "    series = series[series.shape[0] % batch_size:]\n",
    "    close = series[['Time', 'Real Close', 'Close']]\n",
    "    close = close.copy()\n",
    "    close['PrevClose'] = close['Close'].shift(1)\n",
    "\n",
    "    series = series.drop(['Time', 'Real Close'], axis=1)\n",
    "    series = series[['Close', 'EMA_10', 'EMA_50', 'RSI', 'A/D Index',\n",
    "                     '{} Interest Rate'.format(buy), '{} Interest Rate'.format(sell), '{}_CPI'.format(buy), '{}_CPI'.format(sell),\n",
    "                     '{} Twitter Sentiment'.format(buy), '{} Twitter Sentiment'.format(sell),\n",
    "                     '{} News Sentiment'.format(buy), '{} News Sentiment'.format(sell),\n",
    "                     #'EUR_GDP', 'USD_GDP', 'EUR Unemployment Rate', 'USD Unemployment Rate', 'EUR_PPI', 'USD_PPI'\n",
    "                    ]]\n",
    "\n",
    "    df_train, df_val, df_test = create_split(series, 0.75, 0.1, batch_size, window_size)\n",
    "    print(f'df_train.shape {df_train.shape}, df_validation.shape {df_val.shape}, df_test.shape {df_test.shape}')\n",
    "    df_test = df_test.copy()\n",
    "    df_test.loc[:, ['Close']] = scaler.transform(df_test[['Close']])\n",
    "    df_test.loc[:, ~df_test.columns.isin(['Close'])] = fScaler.transform(df_test.loc[:, ~df_test.columns.isin(['Close'])])\n",
    "    \n",
    "    X_test, y_test = create_dataset(df_test, window_size)\n",
    "    #X_test, y_test = create_multi_pred_dataset(df_test, window_size, 5)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    multi_pred = flatten_prediction(y_pred, y_test.shape[0], time_steps)\n",
    "    evaluate_forecast(multi_pred, y_test)\n",
    "\n",
    "    #mse = model.evaluate(X_test, y_test)\n",
    "    #print(\"Test Mean Squared Error:\", mse)\n",
    "\n",
    "    index = [i for i in range(multi_pred.shape[0])]\n",
    "    df_predicted = pd.DataFrame(scaler.inverse_transform(multi_pred.reshape(-1, 1)), columns=['Close'], index=index)\n",
    "    df_actual = pd.DataFrame(scaler.inverse_transform(y_test.reshape(-1, 1)), columns=['Close'], index=index)\n",
    "\n",
    "    df = pd.DataFrame(close[-multi_pred.shape[0] - window_size:])\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    #print(df_test[['Close']][:20])\n",
    "    #print(scaler.inverse_transform(df_test[['Close']])[:20])\n",
    "    #print(scaler.inverse_transform(y_test.reshape(-1, 1))[:20])\n",
    "    \n",
    "    df = df[window_size:]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    #print(df[:20])\n",
    "    df['rip'] = df_actual['Close']\n",
    "    \n",
    "    #df_predicted['Close'] = df['Real Close'].mul(np.exp(df_predicted['Close'].shift(-1))).shift(1)\n",
    "    df_actual = df['Real Close'].mul(np.exp(df['Close']).shift(-1)).shift(1)\n",
    "    print(df[:20])\n",
    "    print(df_actual[:20])\n",
    "\n",
    "    \n",
    "    #evaluate_forecast(df_predicted['Close'].iloc[1:], df_actual['Close'].iloc[1:])\n",
    "\n",
    "    #return df_predicted, df_actual\n",
    "    \n",
    "    #index = [i for i in range(y_pred.shape[0])]\n",
    "    #df_predicted = pd.DataFrame(scaler.inverse_transform(y_pred), columns=['Close'], index=index)\n",
    "    #df_actual = pd.DataFrame(scaler.inverse_transform(y_test.reshape(-1, 1)), columns=['Close'], index=index)\n",
    "    \n",
    "    #df = pd.DataFrame(close['Real Close'][-y_pred.shape[0] - window_size:-window_size])\n",
    "    #df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    #df_predicted['Close'] = df['Real Close'].mul(np.exp(df_predicted['Close'].shift(-1))).shift(1)\n",
    "    #df_actual['Close'] = df['Real Close'].mul(np.exp(df_actual['Close'].shift(-1))).shift(1)\n",
    "    \n",
    "    #df_predicted['Close'] = df_predicted['Close']\n",
    "    #df_actual['Close'] = df_actual['Close']\n",
    "    \n",
    "    #return df_predicted, df_actual\n",
    "\n",
    "def visualize_prediction(df_predicted, df_actual):\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    ax1 = fig.subplots(1)\n",
    "    ax1.set_title('Predicted Closing Price')\n",
    "    ax1.set(xlabel='Time', ylabel='Close')\n",
    "    ax1.plot(df_actual['Close'][:100], label='Actual')\n",
    "    ax1.plot(df_predicted['Close'][:100], label='Prediction')\n",
    "    ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape (50400, 13), df_validation.shape (5610, 13), df_test.shape (18698, 13)\n",
      "(50384, 10, 13)\n",
      "(50384, 5)\n",
      "(5594, 10, 13)\n",
      "(5594, 5)\n",
      "1575/1575 [==============================] - 16s 10ms/step - loss: 0.0087 - mae: 0.0684 - val_loss: 0.0035 - val_mae: 0.0416\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "window_size = 10\n",
    "nodes = [80, 64, 32, 5]\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "dropout = 0.2\n",
    "epochs = 1\n",
    "\n",
    "model, closeScaler, featureScaler = train_model(\"EURUSD\", batch_size, window_size, nodes, optimizer, dropout, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape (50400, 13), df_validation.shape (5610, 13), df_test.shape (18698, 13)\n",
      "18688 18688\n",
      "Test Mean Squared Error: 0.007084544323230347\n",
      "Test Mean Absolute Error: 0.07748319441465179\n",
      "                         Time  Real Close     Close  PrevClose       rip\n",
      "0   2020-04-02 02:00:00+00:00     1.09369 -0.000603  -0.000603 -0.000603\n",
      "1   2020-04-02 02:15:00+00:00     1.09431  0.000567  -0.000603  0.000567\n",
      "2   2020-04-02 02:30:00+00:00     1.09435  0.000037   0.000567  0.000037\n",
      "3   2020-04-02 02:45:00+00:00     1.09335 -0.000914   0.000037 -0.000914\n",
      "4   2020-04-02 03:00:00+00:00     1.09342  0.000064  -0.000914  0.000064\n",
      "5   2020-04-02 03:15:00+00:00     1.09350  0.000073   0.000064  0.000073\n",
      "6   2020-04-02 03:30:00+00:00     1.09375  0.000229   0.000073  0.000229\n",
      "7   2020-04-02 03:45:00+00:00     1.09376  0.000009   0.000229  0.000009\n",
      "8   2020-04-02 04:00:00+00:00     1.09385  0.000082   0.000009  0.000082\n",
      "9   2020-04-02 04:15:00+00:00     1.09377 -0.000073   0.000082 -0.000073\n",
      "10  2020-04-02 04:30:00+00:00     1.09373 -0.000037  -0.000073 -0.000037\n",
      "11  2020-04-02 04:45:00+00:00     1.09380  0.000064  -0.000037  0.000064\n",
      "12  2020-04-02 05:00:00+00:00     1.09431  0.000466   0.000064  0.000466\n",
      "13  2020-04-02 05:15:00+00:00     1.09452  0.000192   0.000466  0.000192\n",
      "14  2020-04-02 05:30:00+00:00     1.09489  0.000338   0.000192  0.000338\n",
      "15  2020-04-02 05:45:00+00:00     1.09441 -0.000438   0.000338 -0.000438\n",
      "16  2020-04-02 06:00:00+00:00     1.09444  0.000027  -0.000438  0.000027\n",
      "17  2020-04-02 06:15:00+00:00     1.09591  0.001342   0.000027  0.001342\n",
      "18  2020-04-02 06:30:00+00:00     1.09527 -0.000584   0.001342 -0.000584\n",
      "19  2020-04-02 06:45:00+00:00     1.09456 -0.000648  -0.000584 -0.000648\n",
      "0         NaN\n",
      "1     1.09431\n",
      "2     1.09435\n",
      "3     1.09335\n",
      "4     1.09342\n",
      "5     1.09350\n",
      "6     1.09375\n",
      "7     1.09376\n",
      "8     1.09385\n",
      "9     1.09377\n",
      "10    1.09373\n",
      "11    1.09380\n",
      "12    1.09431\n",
      "13    1.09452\n",
      "14    1.09489\n",
      "15    1.09441\n",
      "16    1.09444\n",
      "17    1.09591\n",
      "18    1.09527\n",
      "19    1.09456\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cool = test_model(\"EURUSD\", window_size, batch_size, 5, model, closeScaler, featureScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
