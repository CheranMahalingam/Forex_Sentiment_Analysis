{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "pd.set_option('display.max_rows', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "import re\n",
    "\n",
    "def twitter_dataframe(account):\n",
    "    tweets = pd.read_json(\"../data/raw/tweets/{}_historical.json\".format(account))\n",
    "    headline_arr = []\n",
    "    date_arr = []\n",
    "    \n",
    "    for post in range(tweets[\"headline\"].count()):\n",
    "        headline_arr.append(tweets[\"headline\"].iloc[post])\n",
    "        date_arr.append(tweets[\"date\"].iloc[post])\n",
    "    tweets_df = pd.DataFrame({\"Time\": date_arr, \"Post\": headline_arr})\n",
    "    \n",
    "    tweets_df[\"Post\"] = clean_tweets(tweets_df[\"Post\"])\n",
    "    tweets_df = generate_sentiment_score(tweets_df)\n",
    "    tweets_df[\"Time\"] = tweets_df[\"Time\"].dt.strftime(\"%Y-%m-%d %H:%M\")\n",
    "    \n",
    "    return tweets_df\n",
    "\n",
    "def generate_sentiment_score(tweets):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    score = []\n",
    "    for post in tweets[\"Post\"]:\n",
    "        score.append(sid.polarity_scores(post)[\"compound\"])\n",
    "    tweet_score = pd.DataFrame({\"Twitter_Sentiment\": score})\n",
    "    tweets[\"Twitter_Sentiment\"] = tweet_score\n",
    "    return tweets\n",
    "\n",
    "def clean_tweets(tweets):\n",
    "    tweets = np.vectorize(remove_pattern) (tweets, \"RT @[\\w]*:\")\n",
    "    tweets = np.vectorize(remove_pattern) (tweets, \"@[\\w]*\")\n",
    "    tweets = np.vectorize(remove_pattern) (tweets, \"https?://[A-Za-z0-9./]*\")\n",
    "    tweets = np.core.defchararray.replace(tweets, \"[^a-zA-Z]\", \" \")\n",
    "    tweets = np.core.defchararray.replace(tweets, \"\\n\", \" \")\n",
    "    return tweets\n",
    "    \n",
    "def remove_pattern(input_text, pattern):\n",
    "    r = re.findall(pattern, input_text)\n",
    "    for i in r:\n",
    "        input_text = re.sub(i, \"\", input_text)\n",
    "    return input_text\n",
    "\n",
    "def tweets_merge(tweet_list):\n",
    "    if len(tweet_list) == 0:\n",
    "        return\n",
    "    elif len(tweet_list) == 1:\n",
    "        return tweet_list[0]\n",
    "    else:\n",
    "        merged_tweets = reduce(lambda left, right : pd.merge(left, right, how=\"outer\", on=[\"Time\", \"Post\", \"Twitter_Sentiment\"]), tweet_list)     \n",
    "        merged_tweets.sort_values(by=[\"Time\"], inplace=True)\n",
    "        merged_tweets = merged_tweets.reset_index(drop=True)\n",
    "        return merged_tweets\n",
    "\n",
    "forex_com = twitter_dataframe(\"forexcom\")\n",
    "ft_markets = twitter_dataframe(\"FTMarkets\")\n",
    "bloomberg = twitter_dataframe(\"markets\")\n",
    "reuters = twitter_dataframe(\"ReutersGMF\")\n",
    "wsj = twitter_dataframe(\"WSJmarkets\")\n",
    "fx_street_1 = twitter_dataframe(\"FXstreetNews\")\n",
    "fx_street_2 = twitter_dataframe(\"FXstreetNews2\")\n",
    "tweets = tweets_merge([forex_com, ft_markets, bloomberg, reuters, wsj, fx_street_1, fx_street_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Post</th>\n",
       "      <th>Twitter_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:12</td>\n",
       "      <td>Here are some of the biggest winners and loser...</td>\n",
       "      <td>-0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 11:04</td>\n",
       "      <td>How high-frequency trading hit a speed bump</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 13:19</td>\n",
       "      <td>Cryptocurrencies: debased coinages</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 21:00</td>\n",
       "      <td>Crude Oil Price Forecast 2018: Rally likely to...</td>\n",
       "      <td>-0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 22:18</td>\n",
       "      <td>Option expiries for today's NY cut By   #Curre...</td>\n",
       "      <td>-0.2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182220</th>\n",
       "      <td>2020-12-30 22:57</td>\n",
       "      <td>NZD/USD consolidates at annual highs above 0.7...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182221</th>\n",
       "      <td>2020-12-30 23:17</td>\n",
       "      <td>New investment by SoftBank allows construction...</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182222</th>\n",
       "      <td>2020-12-30 23:18</td>\n",
       "      <td>USTR: Additional tariffs target products from ...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182223</th>\n",
       "      <td>2020-12-30 23:25</td>\n",
       "      <td>USD/CAD Price Analysis: Bears’ shouldn’t ignor...</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182224</th>\n",
       "      <td>2020-12-30 23:45</td>\n",
       "      <td>Brexit deal approved by UK Parliament, GBP/USD...</td>\n",
       "      <td>0.7506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182225 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Time                                               Post  \\\n",
       "0       2018-01-01 00:12  Here are some of the biggest winners and loser...   \n",
       "1       2018-01-01 11:04        How high-frequency trading hit a speed bump   \n",
       "2       2018-01-01 13:19                 Cryptocurrencies: debased coinages   \n",
       "3       2018-01-01 21:00  Crude Oil Price Forecast 2018: Rally likely to...   \n",
       "4       2018-01-01 22:18  Option expiries for today's NY cut By   #Curre...   \n",
       "...                  ...                                                ...   \n",
       "182220  2020-12-30 22:57  NZD/USD consolidates at annual highs above 0.7...   \n",
       "182221  2020-12-30 23:17  New investment by SoftBank allows construction...   \n",
       "182222  2020-12-30 23:18  USTR: Additional tariffs target products from ...   \n",
       "182223  2020-12-30 23:25  USD/CAD Price Analysis: Bears’ shouldn’t ignor...   \n",
       "182224  2020-12-30 23:45  Brexit deal approved by UK Parliament, GBP/USD...   \n",
       "\n",
       "        Twitter_Sentiment  \n",
       "0                 -0.0772  \n",
       "1                  0.0000  \n",
       "2                  0.0000  \n",
       "3                 -0.5719  \n",
       "4                 -0.2732  \n",
       "...                   ...  \n",
       "182220             0.0000  \n",
       "182221            -0.2960  \n",
       "182222             0.0000  \n",
       "182223            -0.4767  \n",
       "182224             0.7506  \n",
       "\n",
       "[182225 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002999844697489368\n",
      "0.3703114281794485\n"
     ]
    }
   ],
   "source": [
    "print(tweets[\"Twitter_Sentiment\"].mean())\n",
    "print(tweets[\"Twitter_Sentiment\"].isin([0]).sum()/tweets[\"Twitter_Sentiment\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for post in tweets[\"Post\"]:\n",
    "    if \"great britain\" in post.lower():\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>USD</th>\n",
       "      <th>AUD</th>\n",
       "      <th>GBP</th>\n",
       "      <th>NZD</th>\n",
       "      <th>CAD</th>\n",
       "      <th>CHF</th>\n",
       "      <th>JPY</th>\n",
       "      <th>EUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 22:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 22:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 22:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 22:03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 22:04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617129</th>\n",
       "      <td>2020-12-31 21:56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617130</th>\n",
       "      <td>2020-12-31 21:57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617131</th>\n",
       "      <td>2020-12-31 21:58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617132</th>\n",
       "      <td>2020-12-31 21:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617133</th>\n",
       "      <td>2018-01-01 21:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1617134 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Time  USD  AUD  GBP  NZD     CAD  CHF  JPY  EUR\n",
       "0        2018-01-01 22:00  0.0  0.0  0.0  0.0  0.0000  0.0  0.0  0.0\n",
       "1        2018-01-01 22:01  0.0  0.0  0.0  0.0  0.0000  0.0  0.0  0.0\n",
       "2        2018-01-01 22:02  0.0  0.0  0.0  0.0  0.0000  0.0  0.0  0.0\n",
       "3        2018-01-01 22:03  0.0  0.0  0.0  0.0  0.0000  0.0  0.0  0.0\n",
       "4        2018-01-01 22:04  0.0  0.0  0.0  0.0  0.0000  0.0  0.0  0.0\n",
       "...                   ...  ...  ...  ...  ...     ...  ...  ...  ...\n",
       "1617129  2020-12-31 21:56  0.0  0.0  0.0  0.0  0.0000  0.0  0.0  0.0\n",
       "1617130  2020-12-31 21:57  0.0  0.0  0.0  0.0  0.0000  0.0  0.0  0.0\n",
       "1617131  2020-12-31 21:58  0.0  0.0  0.0  0.0  0.0000  0.0  0.0  0.0\n",
       "1617132  2020-12-31 21:59  0.0  0.0  0.0  0.0  0.0000  0.0  0.0  0.0\n",
       "1617133  2018-01-01 21:00  0.0  0.0  0.0  0.0 -0.5719  0.0  0.0  0.0\n",
       "\n",
       "[1617134 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def currency_sentiment(currencies_dict):\n",
    "    country_df = pd.DataFrame()\n",
    "    for currency in currencies_dict:\n",
    "        for entity in currencies_dict[currency][\"positive\"]:\n",
    "            tweet_lower = tweets[\"Post\"].transform(lambda post : post.lower())\n",
    "            currency_df = tweets[tweet_lower.str.contains(entity)]\n",
    "            currency_df = currency_df[{\"Time\", \"Twitter_Sentiment\"}]\n",
    "            currency_df = currency_df.rename(columns={\"Twitter_Sentiment\": currency.upper()})\n",
    "            if country_df.empty:\n",
    "                country_df = currency_df\n",
    "            elif not currency.upper() in country_df.columns:\n",
    "                country_df = country_df.merge(currency_df, how=\"outer\", on=\"Time\")\n",
    "            else:\n",
    "                country_df = country_df.merge(currency_df, how=\"outer\", on=[\"Time\", currency.upper()])\n",
    "        for entity in currencies_dict[currency][\"negative\"]:\n",
    "            tweet_lower = tweets[\"Post\"].transform(lambda post : post.lower())\n",
    "            currency_df = tweets[tweet_lower.str.contains(entity)]\n",
    "            currency_df = currency_df[{\"Time\", \"Twitter_Sentiment\"}]\n",
    "            currency_df[\"Twitter_Sentiment\"] = currency_df[\"Twitter_Sentiment\"].transform(lambda score : -score)\n",
    "            currency_df = currency_df.rename(columns={\"Twitter_Sentiment\": currency.upper()})\n",
    "            if country_df.empty:\n",
    "                country_df = currency_df\n",
    "            elif not currency.upper() in country_df.columns:\n",
    "                country_df = country_df.merge(currency_df, how=\"outer\", on=\"Time\")\n",
    "            else:\n",
    "                country_df = country_df.merge(currency_df, how=\"outer\", on=[\"Time\", currency.upper()])\n",
    "                \n",
    "    time_frame = pd.date_range(start=\"2018-01-01 22:00:00\", freq=\"1T\", end=\"2020-12-31 21:59:00\")\n",
    "    time_frame = pd.DataFrame(time_frame, columns=[\"Time\"])\n",
    "    time_frame[\"Time\"] = time_frame[\"Time\"].dt.strftime(\"%Y-%m-%d %H:%M\")\n",
    "    \n",
    "    country_df = time_frame.merge(country_df, how=\"outer\", on=\"Time\")\n",
    "    country_df = country_df.fillna(0)\n",
    "    \n",
    "    return country_df\n",
    "    \n",
    "            \n",
    "currencies = {\n",
    "              \"usd\": {\"positive\": [\"usd/\", \"u.s.\", \"greenback\", \"buck\", \"barnie\", \"america\", \"united states\"], \"negative\": [\"/usd\", \"cable\"]},\n",
    "              \"aud\": {\"positive\": [\"aud/\", \"gold\", \"aussie\", \"australia\"], \"negative\": [\"/aud\"]}, \n",
    "              \"gbp\": {\"positive\": [\"gbp/\", \"sterling\", \"pound\", \"u.k.\", \"united kingdom\", \"cable\", \"guppy\"], \"negative\": [\"/gbp\"]},\n",
    "              \"nzd\": {\"positive\": [\"nzd/\", \"gold\", \"kiwi\", \"new zealand\"], \"negative\": [\"/nzd\"]},\n",
    "              \"cad\": {\"positive\": [\"cad/\", \"oil\", \"loonie\", \"canada\"], \"negative\": [\"/cad\"]},\n",
    "              \"chf\": {\"positive\": [\"chf/\", \"swiss\"], \"negative\": [\"/chf\"]},\n",
    "              \"jpy\": {\"positive\": [\"jpy/\", \"asian\", \"japan\"], \"negative\": [\"/jpy\", \"guppy\"]},\n",
    "              \"eur\": {\"positive\": [\"eur/\", \"fiber\", \"euro\"], \"negative\": [\"/eur\"]}\n",
    "             }\n",
    "currency_sentiment = currency_sentiment(currencies)\n",
    "currency_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13529"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(currency_sentiment[\"EUR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_sentiment.to_csv(\"../data/processed/tweets/tweets_sentiment.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
